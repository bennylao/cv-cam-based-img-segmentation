{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a6460a86",
      "metadata": {
        "id": "a6460a86"
      },
      "source": [
        "# Fully Supervised DeepLabv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a48708f7",
      "metadata": {
        "id": "a48708f7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import json\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e024487f",
      "metadata": {
        "id": "e024487f"
      },
      "outputs": [],
      "source": [
        "def get_root_dir(cwd: pathlib.Path = pathlib.Path().resolve(), anchor=\"README.md\") -> pathlib.Path:\n",
        "    \"\"\"\n",
        "    Get the root directory of the project by searching for a specific anchor file.\n",
        "    i.e. find the root directory where anchor file README.md/.git is located.\n",
        "\n",
        "    Args:\n",
        "        cwd (pathlib.Path): Current working directory.\n",
        "        anchor (str): The name of the anchor file to search for.\n",
        "\n",
        "    Returns:\n",
        "        pathlib.Path: The root directory of the project.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the anchor file is not found in any parent directories.\n",
        "    \"\"\"\n",
        "    # Check if the anchor file exists in the current working directory\n",
        "    # If it does, return the current working directory\n",
        "    # If it doesn't, check the parent directories until the anchor file is found\n",
        "    if cwd.joinpath(anchor).exists():\n",
        "        return cwd\n",
        "    else:\n",
        "        for parent in cwd.parents:\n",
        "            if (parent / anchor).exists():\n",
        "                return parent\n",
        "\n",
        "    # If the anchor file is not found in any parent directories, raise an error\n",
        "    raise FileNotFoundError(f\"Anchor file '{anchor}' not found in any parent directories of {cwd}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1e50a417",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e50a417",
        "outputId": "de7c9ae0-8014-41aa-98e6-35a6096eeb68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "==================================================\n",
            "Runtime: Google Colab\n",
            "CURRENT_PATH=PosixPath('/content')\n",
            "ROOT=PosixPath('/content/cv-cam-based-img-segmentation')\n",
            "DATA_DIR=PosixPath('/content/cv-cam-based-img-segmentation/data')\n",
            "MODEL_DIR=PosixPath('/content/drive/MyDrive/Colab Notebooks/models')\n",
            "OUTPUT_DIR=PosixPath('/content/drive/MyDrive/Colab Notebooks/output')\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Git repository information\n",
        "REPO_GIT_OWNER = \"bennylao\"\n",
        "REPO_NAME = \"cv-cam-based-img-segmentation\"\n",
        "\n",
        "\n",
        "### Logics to set up paths based on the environment (Google Colab or local machine) ###\n",
        "COLAB_ROOT_PATH = pathlib.Path(\"/content\")\n",
        "IS_COLAB = COLAB_ROOT_PATH.exists()\n",
        "\n",
        "if IS_COLAB:\n",
        "    # Working on Google Colab\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Mount Google Drive\n",
        "    DRIVE_PATH = COLAB_ROOT_PATH.joinpath(\"drive\")\n",
        "    drive.flush_and_unmount()\n",
        "    drive.mount(str(DRIVE_PATH))\n",
        "\n",
        "    # Load git credentials from Google Drive\n",
        "    DRIVE_FOLDER_PATH = DRIVE_PATH.joinpath(\"MyDrive\", \"Colab Notebooks\")\n",
        "    if DRIVE_FOLDER_PATH.exists():\n",
        "        with open(DRIVE_FOLDER_PATH.joinpath(\"git_credentials.json\"), \"r\") as f:\n",
        "            git_config = json.load(f)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Config file not found at {DRIVE_FOLDER_PATH}\")\n",
        "\n",
        "    # Set up Git credentials\n",
        "    GIT_USER_NAME = git_config[\"GIT_USER_NAME\"]\n",
        "    GIT_TOKEN = git_config[\"GIT_TOKEN\"]\n",
        "    GIT_USER_EMAIL = git_config[\"GIT_USER_EMAIL\"]\n",
        "\n",
        "    !git config --global user.email {GIT_USER_EMAIL}\n",
        "    !git config --global user.name {GIT_USER_NAME}\n",
        "\n",
        "    # Set up project paths\n",
        "    CURRENT_PATH = pathlib.Path().resolve()\n",
        "    ROOT = COLAB_ROOT_PATH.joinpath(REPO_NAME)\n",
        "    DATA_DIR = ROOT.joinpath(\"data\")\n",
        "    MODEL_DIR = DRIVE_FOLDER_PATH.joinpath(\"models\")\n",
        "    OUTPUT_DIR = DRIVE_FOLDER_PATH.joinpath(\"output\")\n",
        "\n",
        "    # Clone repo\n",
        "    GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{REPO_GIT_OWNER}/{REPO_NAME}.git\"\n",
        "\n",
        "    if not ROOT.exists():\n",
        "        !git clone --depth 1 \"{GIT_PATH}\" \"{ROOT}\"\n",
        "\n",
        "else:\n",
        "    # Working on local machine\n",
        "    CURRENT_PATH = pathlib.Path().resolve()\n",
        "    ROOT = get_root_dir(CURRENT_PATH, anchor=\"README.md\")\n",
        "    DATA_DIR = ROOT.joinpath(\"data\")\n",
        "    MODEL_DIR = ROOT.joinpath(\"models\")\n",
        "    OUTPUT_DIR = ROOT.joinpath(\"output\")\n",
        "\n",
        "# Create folder if not exist\n",
        "if not DATA_DIR.exists():\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created data directory at {DATA_DIR}\")\n",
        "\n",
        "if not OUTPUT_DIR.exists():\n",
        "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created output directory at {OUTPUT_DIR}\")\n",
        "\n",
        "if not MODEL_DIR.exists():\n",
        "    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created model directory at {MODEL_DIR}\")\n",
        "\n",
        "# Add root path to sys.path\n",
        "sys.path.append(str(ROOT))\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"Runtime: {'Google Colab' if IS_COLAB else 'Local Machine'}\")\n",
        "print(f\"{CURRENT_PATH=}\")\n",
        "print(f\"{ROOT=}\")\n",
        "print(f\"{DATA_DIR=}\")\n",
        "print(f\"{MODEL_DIR=}\")\n",
        "print(f\"{OUTPUT_DIR=}\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6498a9e3",
      "metadata": {
        "id": "6498a9e3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "from tqdm import tqdm\n",
        "from src import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "41ca25ac",
      "metadata": {
        "id": "41ca25ac"
      },
      "outputs": [],
      "source": [
        "# Set Hyperparameters\n",
        "IMAGE_SIZE = 256\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "TRAIN_EPOCHS = 10\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "TEST_BATCH_SIZE = 64\n",
        "NUM_WORKERS = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d45476cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d45476cc",
        "outputId": "8120878b-b94d-4577-dbc1-7aebae3a4ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pin_memory = True if torch.cuda.is_available() else False\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define transforms\n",
        "train_transforms = utils.Compose([\n",
        "    utils.PILToTensor(),\n",
        "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    utils.ConvertMaskToBinary(),\n",
        "    utils.RandomHorizontalFlip(flip_prob=0.5),\n",
        "    utils.RandomVerticalFlip(flip_prob=0.5),\n",
        "    utils.RandomRotation(degrees=30),\n",
        "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "test_transforms = utils.Compose([\n",
        "    utils.PILToTensor(),\n",
        "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    utils.ConvertMaskToBinary(),\n",
        "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "trainset, testset = utils.construct_dataset(\n",
        "    data_dir=DATA_DIR,\n",
        "    train_transforms=train_transforms,\n",
        "    test_transforms=test_transforms,\n",
        ")\n",
        "trainloader = DataLoader(\n",
        "    trainset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "testloader = DataLoader(\n",
        "    testset,\n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "# Load model\n",
        "model = deeplabv3_resnet50(weights=None)\n",
        "model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(\n",
        "    model.parameters(), lr=0.01,\n",
        "    momentum=0.9,\n",
        "    weight_decay=1e-4,\n",
        "    nesterov=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7f4a5800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f4a5800",
        "outputId": "671c668d-8d91-4e6e-9dee-3c8bf74bb5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:27<00:00,  2.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.1337, mIoU: 0.8276\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:26<00:00,  3.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Loss: 0.1189, mIoU: 0.8946\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:26<00:00,  3.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Loss: 0.1137, mIoU: 0.9053\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:26<00:00,  3.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Loss: 0.0871, mIoU: 0.9136\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:26<00:00,  3.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Loss: 0.1121, mIoU: 0.9170\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/baseline_deeplab_epoch_5.pth\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:26<00:00,  3.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Loss: 0.0813, mIoU: 0.9215\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:26<00:00,  3.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Loss: 0.1061, mIoU: 0.9243\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:26<00:00,  3.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Loss: 0.1327, mIoU: 0.9266\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:26<00:00,  3.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/10], Loss: 0.0857, mIoU: 0.9282\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 81/81 [00:26<00:00,  3.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/10], Loss: 0.1102, mIoU: 0.9298\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/baseline_deeplab_epoch_10.pth\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "model.train()\n",
        "num_train_samples = len(trainloader.dataset)\n",
        "\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{TRAIN_EPOCHS}\")\n",
        "    miou = 0\n",
        "    for i, (images, segs, _, _) in enumerate(tqdm(trainloader)):\n",
        "        images = images.to(device)\n",
        "        segs = segs.to(device)\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)[\"out\"]\n",
        "        loss = loss_fn(outputs, segs)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.argmax(outputs, dim=1)\n",
        "        miou += utils.mean_iou(pred, segs, num_classes=NUM_CLASSES) * batch_size\n",
        "\n",
        "    miou /= num_train_samples\n",
        "    print(f\"Epoch [{epoch + 1}/{TRAIN_EPOCHS}], Loss: {loss.item():.4f}, mIoU: {miou:.4f}\")\n",
        "\n",
        "    # Save model checkpoint\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        save_path = MODEL_DIR.joinpath(f\"baseline_deeplab_epoch_{epoch + 1}.pth\")\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Model saved at {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fQq6SzcyjWgj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQq6SzcyjWgj",
        "outputId": "663e27f3-3f4b-4208-fbd4-4352e6ac7ec6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:06<00:00,  5.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: baseline_deeplab_epoch_5.pth,Mean IoU: 0.9178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:05<00:00,  5.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: baseline_deeplab_epoch_10.pth,Mean IoU: 0.9229\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "save_epochs = torch.arange(5, TRAIN_EPOCHS + 1, 5)\n",
        "\n",
        "for epoch in save_epochs:\n",
        "    model_name = f\"baseline_deeplab_epoch_{epoch}.pth\"\n",
        "\n",
        "    # Load model\n",
        "    model = deeplabv3_resnet50(weights=None)\n",
        "    model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
        "    model.load_state_dict(torch.load(MODEL_DIR.joinpath(model_name), weights_only=True))\n",
        "    model.to(device)\n",
        "\n",
        "    # Evaluate model\n",
        "    model.eval()\n",
        "    num_test_samples = len(testloader.dataset)\n",
        "    miou = 0\n",
        "    with torch.no_grad():\n",
        "        for images, segs, _, _ in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            segs = segs.to(device)\n",
        "            batch_size = images.size(0)\n",
        "\n",
        "            outputs = model(images)[\"out\"]\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            miou += utils.mean_iou(preds, segs, num_classes=NUM_CLASSES) * batch_size\n",
        "\n",
        "        miou /= num_test_samples\n",
        "        print(f\"Model: {model_name},Mean IoU: {miou:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
