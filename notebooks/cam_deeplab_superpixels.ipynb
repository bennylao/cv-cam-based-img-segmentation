{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a6460a86",
      "metadata": {
        "id": "a6460a86"
      },
      "source": [
        "# Fully Supervised DeepLabv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a48708f7",
      "metadata": {
        "id": "a48708f7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import json\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e024487f",
      "metadata": {
        "id": "e024487f"
      },
      "outputs": [],
      "source": [
        "def get_root_dir(cwd: pathlib.Path = pathlib.Path().resolve(), anchor=\"README.md\") -> pathlib.Path:\n",
        "    \"\"\"\n",
        "    Get the root directory of the project by searching for a specific anchor file.\n",
        "    i.e. find the root directory where anchor file README.md/.git is located.\n",
        "\n",
        "    Args:\n",
        "        cwd (pathlib.Path): Current working directory.\n",
        "        anchor (str): The name of the anchor file to search for.\n",
        "\n",
        "    Returns:\n",
        "        pathlib.Path: The root directory of the project.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the anchor file is not found in any parent directories.\n",
        "    \"\"\"\n",
        "    # Check if the anchor file exists in the current working directory\n",
        "    # If it does, return the current working directory\n",
        "    # If it doesn't, check the parent directories until the anchor file is found\n",
        "    if cwd.joinpath(anchor).exists():\n",
        "        return cwd\n",
        "    else:\n",
        "        for parent in cwd.parents:\n",
        "            if (parent / anchor).exists():\n",
        "                return parent\n",
        "\n",
        "    # If the anchor file is not found in any parent directories, raise an error\n",
        "    raise FileNotFoundError(f\"Anchor file '{anchor}' not found in any parent directories of {cwd}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "1e50a417",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e50a417",
        "outputId": "de7c9ae0-8014-41aa-98e6-35a6096eeb68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Runtime: Local Machine\n",
            "CURRENT_PATH=PosixPath('/home/benny/vscode-projects/cv-cam-based-img-segmentation/notebooks')\n",
            "ROOT=PosixPath('/home/benny/vscode-projects/cv-cam-based-img-segmentation')\n",
            "DATA_DIR=PosixPath('/home/benny/vscode-projects/cv-cam-based-img-segmentation/data')\n",
            "MODEL_DIR=PosixPath('/home/benny/vscode-projects/cv-cam-based-img-segmentation/models')\n",
            "OUTPUT_DIR=PosixPath('/home/benny/vscode-projects/cv-cam-based-img-segmentation/output')\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Git repository information\n",
        "REPO_GIT_OWNER = \"bennylao\"\n",
        "REPO_NAME = \"cv-cam-based-img-segmentation\"\n",
        "\n",
        "\n",
        "### Logics to set up paths based on the environment (Google Colab or local machine) ###\n",
        "COLAB_ROOT_PATH = pathlib.Path(\"/content\")\n",
        "IS_COLAB = COLAB_ROOT_PATH.exists()\n",
        "\n",
        "if IS_COLAB:\n",
        "    # Working on Google Colab\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Mount Google Drive\n",
        "    DRIVE_PATH = COLAB_ROOT_PATH.joinpath(\"drive\")\n",
        "    drive.flush_and_unmount()\n",
        "    drive.mount(str(DRIVE_PATH))\n",
        "\n",
        "    # Load git credentials from Google Drive\n",
        "    DRIVE_FOLDER_PATH = DRIVE_PATH.joinpath(\"MyDrive\", \"Colab Notebooks\")\n",
        "    if DRIVE_FOLDER_PATH.exists():\n",
        "        with open(DRIVE_FOLDER_PATH.joinpath(\"git_credentials.json\"), \"r\") as f:\n",
        "            git_config = json.load(f)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Config file not found at {DRIVE_FOLDER_PATH}\")\n",
        "\n",
        "    # Set up Git credentials\n",
        "    GIT_USER_NAME = git_config[\"GIT_USER_NAME\"]\n",
        "    GIT_TOKEN = git_config[\"GIT_TOKEN\"]\n",
        "    GIT_USER_EMAIL = git_config[\"GIT_USER_EMAIL\"]\n",
        "\n",
        "    !git config --global user.email {GIT_USER_EMAIL}\n",
        "    !git config --global user.name {GIT_USER_NAME}\n",
        "\n",
        "    # Set up project paths\n",
        "    CURRENT_PATH = pathlib.Path().resolve()\n",
        "    ROOT = COLAB_ROOT_PATH.joinpath(REPO_NAME)\n",
        "    DATA_DIR = ROOT.joinpath(\"data\")\n",
        "    MODEL_DIR = DRIVE_FOLDER_PATH.joinpath(\"models\")\n",
        "    OUTPUT_DIR = DRIVE_FOLDER_PATH.joinpath(\"output\")\n",
        "\n",
        "    # Clone repo\n",
        "    GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{REPO_GIT_OWNER}/{REPO_NAME}.git\"\n",
        "\n",
        "    if not ROOT.exists():\n",
        "        !git clone --depth 1 \"{GIT_PATH}\" \"{ROOT}\"\n",
        "\n",
        "else:\n",
        "    # Working on local machine\n",
        "    CURRENT_PATH = pathlib.Path().resolve()\n",
        "    ROOT = get_root_dir(CURRENT_PATH, anchor=\"README.md\")\n",
        "    DATA_DIR = ROOT.joinpath(\"data\")\n",
        "    MODEL_DIR = ROOT.joinpath(\"models\")\n",
        "    OUTPUT_DIR = ROOT.joinpath(\"output\")\n",
        "\n",
        "# Create folder if not exist\n",
        "if not DATA_DIR.exists():\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created data directory at {DATA_DIR}\")\n",
        "\n",
        "if not OUTPUT_DIR.exists():\n",
        "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created output directory at {OUTPUT_DIR}\")\n",
        "\n",
        "if not MODEL_DIR.exists():\n",
        "    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created model directory at {MODEL_DIR}\")\n",
        "\n",
        "# Add root path to sys.path\n",
        "sys.path.append(str(ROOT))\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"Runtime: {'Google Colab' if IS_COLAB else 'Local Machine'}\")\n",
        "print(f\"{CURRENT_PATH=}\")\n",
        "print(f\"{ROOT=}\")\n",
        "print(f\"{DATA_DIR=}\")\n",
        "print(f\"{MODEL_DIR=}\")\n",
        "print(f\"{OUTPUT_DIR=}\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6498a9e3",
      "metadata": {
        "id": "6498a9e3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from skimage.segmentation import slic\n",
        "from skimage.morphology import opening, closing, disk\n",
        "from src import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ca25ac",
      "metadata": {
        "id": "41ca25ac"
      },
      "outputs": [],
      "source": [
        "# Set Hyperparameters\n",
        "IMAGE_SIZE = 256\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "TRAIN_EPOCHS = 10\n",
        "TRAIN_BATCH_SIZE = 128\n",
        "TEST_BATCH_SIZE = 128\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Path to cam dataset\n",
        "model_name = \"cam_deeplab_epoch_5.pth\"\n",
        "CAM_DIR = DATA_DIR.joinpath(\"cam_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d45476cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d45476cc",
        "outputId": "8120878b-b94d-4577-dbc1-7aebae3a4ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pin_memory = True if torch.cuda.is_available() else False\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define transforms\n",
        "train_transforms = utils.Compose([\n",
        "    utils.PILToTensor(),\n",
        "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    utils.ConvertMaskToBinary(),\n",
        "    utils.RandomHorizontalFlip(flip_prob=0.5),\n",
        "    utils.RandomVerticalFlip(flip_prob=0.5),\n",
        "    utils.RandomRotation(degrees=30),\n",
        "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
        "    utils.FormatCAM(isRaw=False),\n",
        "])\n",
        "test_transforms = utils.Compose([\n",
        "    utils.PILToTensor(),\n",
        "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    utils.ConvertMaskToBinary(),\n",
        "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
        "    utils.FormatCAM(isRaw=False),\n",
        "])\n",
        "superpixel_transforms = utils.Compose([\n",
        "\tutils.PILToTensor(),\n",
        "\tutils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "\tutils.ToDtype(dtype=torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "trainset, testset = utils.construct_dataset(\n",
        "    data_dir=DATA_DIR,\n",
        "    train_transforms=train_transforms,\n",
        "    test_transforms=test_transforms,\n",
        "    cam_dir=CAM_DIR,\n",
        "    raw_cam=False,\n",
        ")\n",
        "trainloader = DataLoader(\n",
        "    trainset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "testloader = DataLoader(\n",
        "    testset,\n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "with open(DATA_DIR / \"train_ids.json\", \"r\") as f:\n",
        "    train_ids = json.load(f)\n",
        "\n",
        "# Load model\n",
        "model = deeplabv3_resnet50(weights=None)\n",
        "model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
        "model.load_state_dict(torch.load(MODEL_DIR.joinpath(model_name), weights_only=True))\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(\n",
        "    model.parameters(), \n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "590e6d72",
      "metadata": {},
      "source": [
        "## Train deeplabv3 on the generated CAM masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a11126ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "def refine_with_soft_voting( # summs probability per class instead of class values + opening and closing smoothing\n",
        "    image_tensor,\n",
        "    prob_map,\n",
        "    n_segments: int = 200,\n",
        "    compactness: float = 10.0,\n",
        "    sigma: float = 1.0,\n",
        "    selem_radius: int = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Refine a per-pixel probability map by superpixel soft-voting, with smoothing.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image_tensor : torch.Tensor\n",
        "        Input image in CHW format ([3, H, W]).\n",
        "    prob_map : np.ndarray\n",
        "        Softmax output of shape (H, W, C) giving per-pixel class probabilities.\n",
        "    n_segments : int\n",
        "        Number of superpixels for SLIC.\n",
        "    compactness : float\n",
        "        Compactness parameter for SLIC.\n",
        "    sigma : float\n",
        "        Gaussian smoothing parameter for SLIC.\n",
        "    selem_radius : int or None\n",
        "        Radius for morphological opening+closing. If None, no smoothing is done.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    smoothed : np.ndarray or None\n",
        "        If `selem_radius` is given, the result after opening+closing, else None.\n",
        "    refined : np.ndarray\n",
        "        Hard labels after superpixel soft-voting, shape (H, W), dtype int.\n",
        "    superpixels : np.ndarray\n",
        "        The SLIC label map, shape (H, W), dtype int.\n",
        "    \"\"\"\n",
        "    # Convert image tensor to HWC numpy\n",
        "    img = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    prob = prob_map.permute(1, 2, 0).cpu().numpy()  # Convert to HWC\n",
        "\n",
        "    # 1) Compute superpixels\n",
        "    superpixels = slic(\n",
        "        img,\n",
        "        n_segments=n_segments,\n",
        "        compactness=compactness,\n",
        "        sigma=sigma,\n",
        "        start_label=0\n",
        "    )\n",
        "    # print(f\"SLIC produced {superpixels.max()+1} superpixels; shape = {superpixels.shape}\")\n",
        "\n",
        "    # 2) Soft‐voting within each superpixel\n",
        "    H, W, C = prob.shape\n",
        "    refined = np.zeros((H, W), dtype=np.int32)\n",
        "    for sp_val in np.unique(superpixels):\n",
        "        mask = (superpixels == sp_val)\n",
        "        sp_probs = prob[mask]           # shape: (n_pixels_in_sp, C)\n",
        "        summed = sp_probs.sum(axis=0)       # shape: (C,)\n",
        "        refined[mask] = np.argmax(summed)\n",
        "\n",
        "    # 3) Optional morphological smoothing\n",
        "    smoothed = None\n",
        "    if selem_radius is not None:\n",
        "        selem = disk(selem_radius)\n",
        "        # Opening then closing to remove small islands & fill gaps\n",
        "        smooth0 = opening(refined.astype(np.uint8), selem)\n",
        "        smoothed = closing(smooth0, selem)\n",
        "\n",
        "    return smoothed, refined, superpixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7f4a5800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f4a5800",
        "outputId": "671c668d-8d91-4e6e-9dee-3c8bf74bb5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [11:08<00:00,  7.70it/s]  \n",
            "100%|██████████| 643/643 [03:01<00:00,  3.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.3499, mIoU: 0.6976\n",
            "Model saved at /home/benny/vscode-projects/cv-cam-based-img-segmentation/models/cam_deeplab_epoch_1.pth\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 41/5144 [00:04<09:58,  8.53it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m             output = model(image.unsqueeze(\u001b[32m0\u001b[39m))[\u001b[33m\"\u001b[39m\u001b[33mout\u001b[39m\u001b[33m\"\u001b[39m].cpu().squeeze(\u001b[32m0\u001b[39m)\n\u001b[32m     22\u001b[39m             \u001b[38;5;66;03m# Refine masks with superpixels and some smoothing\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m             better_seg, _, _  = \u001b[43mrefine_with_soft_voting\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m                \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m\t\t\t\t\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mn_segments\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mcompactness\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m\t\t\t\t\u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m\t\t\t\t\u001b[49m\u001b[43mselem_radius\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\n\u001b[32m     30\u001b[39m \u001b[43m\t\t\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m             image_id = train_ids[i]\n\u001b[32m     33\u001b[39m             \u001b[38;5;66;03m# Save masks as PNGs\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mrefine_with_soft_voting\u001b[39m\u001b[34m(image_tensor, prob_map, n_segments, compactness, sigma, selem_radius)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# Opening then closing to remove small islands & fill gaps\u001b[39;00m\n\u001b[32m     64\u001b[39m     smooth0 = opening(refined.astype(np.uint8), selem)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     smoothed = \u001b[43mclosing\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmooth0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m smoothed, refined, superpixels\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode-projects/cv-cam-based-img-segmentation/.venv/lib/python3.12/site-packages/skimage/morphology/misc.py:50\u001b[39m, in \u001b[36mdefault_footprint.<locals>.func_out\u001b[39m\u001b[34m(image, footprint, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m footprint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     49\u001b[39m     footprint = ndi.generate_binary_structure(image.ndim, \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode-projects/cv-cam-based-img-segmentation/.venv/lib/python3.12/site-packages/skimage/morphology/gray.py:515\u001b[39m, in \u001b[36mclosing\u001b[39m\u001b[34m(image, footprint, out, mode, cval)\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return grayscale morphological closing of an image.\u001b[39;00m\n\u001b[32m    446\u001b[39m \n\u001b[32m    447\u001b[39m \u001b[33;03mThe morphological closing of an image is defined as a dilation followed by\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    512\u001b[39m \n\u001b[32m    513\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    514\u001b[39m footprint = pad_footprint(footprint, pad_end=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m dilated = \u001b[43mdilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    516\u001b[39m out = erosion(dilated, mirror_footprint(footprint), out=out, mode=mode, cval=cval)\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode-projects/cv-cam-based-img-segmentation/.venv/lib/python3.12/site-packages/skimage/morphology/misc.py:50\u001b[39m, in \u001b[36mdefault_footprint.<locals>.func_out\u001b[39m\u001b[34m(image, footprint, *args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m footprint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     49\u001b[39m     footprint = ndi.generate_binary_structure(image.ndim, \u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode-projects/cv-cam-based-img-segmentation/.venv/lib/python3.12/site-packages/skimage/morphology/gray.py:355\u001b[39m, in \u001b[36mdilation\u001b[39m\u001b[34m(image, footprint, out, shift_x, shift_y, mode, cval)\u001b[39m\n\u001b[32m    352\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _footprint_is_sequence(footprint):\n\u001b[32m    353\u001b[39m     footprint = [(footprint, \u001b[32m1\u001b[39m)]\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m out = \u001b[43m_iterate_gray_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgray_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mndi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrey_dilation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfootprints\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode-projects/cv-cam-based-img-segmentation/.venv/lib/python3.12/site-packages/skimage/morphology/gray.py:25\u001b[39m, in \u001b[36m_iterate_gray_func\u001b[39m\u001b[34m(gray_func, image, footprints, out, mode, cval)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Helper to call `gray_func` for each footprint in a sequence.\u001b[39;00m\n\u001b[32m     20\u001b[39m \n\u001b[32m     21\u001b[39m \u001b[33;03m`gray_func` is a morphology function that accepts `footprint`, `output`,\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m`mode` and `cval` keyword arguments (e.g. `scipy.ndimage.grey_erosion`).\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m fp, num_iter = footprints[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mgray_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, num_iter):\n\u001b[32m     27\u001b[39m     gray_func(out.copy(), footprint=fp, output=out, mode=mode, cval=cval)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode-projects/cv-cam-based-img-segmentation/.venv/lib/python3.12/site-packages/scipy/ndimage/_morphology.py:1440\u001b[39m, in \u001b[36mgrey_dilation\u001b[39m\u001b[34m(input, size, footprint, structure, output, mode, cval, origin, axes)\u001b[39m\n\u001b[32m   1437\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sz & \u001b[32m1\u001b[39m:\n\u001b[32m   1438\u001b[39m         origin[ii] -= \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1440\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filters\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_min_or_max_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m                                   \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/vscode-projects/cv-cam-based-img-segmentation/.venv/lib/python3.12/site-packages/scipy/ndimage/_filters.py:1386\u001b[39m, in \u001b[36m_min_or_max_filter\u001b[39m\u001b[34m(input, size, footprint, structure, output, mode, cval, origin, minimum, axes)\u001b[39m\n\u001b[32m   1382\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1383\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mA sequence of modes is not supported for non-separable \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1384\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfootprints\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1385\u001b[39m     mode = _ni_support._extend_mode_to_code(mode)\n\u001b[32m-> \u001b[39m\u001b[32m1386\u001b[39m     \u001b[43m_nd_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmin_or_max_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfootprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminimum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m temp_needed:\n\u001b[32m   1389\u001b[39m     temp[...] = output\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "num_train_samples = len(trainloader.dataset)\n",
        "\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{TRAIN_EPOCHS}\")\n",
        "    miou = 0\n",
        "    # Configure the path where new pseudo masks are saved\n",
        "    save_dir = DATA_DIR / f\"superpixel_refined_mask_{epoch}\"\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ### Generate refined masks for training\n",
        "    model.eval()\n",
        "    trainloader.dataset.transforms = superpixel_transforms\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(train_ids))):\n",
        "\n",
        "            image, _, _, _ = trainloader.dataset[i]\n",
        "            image = image.to(device)\n",
        "\n",
        "            output = model(image.unsqueeze(0))[\"out\"].cpu().squeeze(0)\n",
        "\n",
        "            # Refine masks with superpixels and some smoothing\n",
        "            better_seg, _, _  = refine_with_soft_voting(\n",
        "                image.cpu(),\n",
        "\t\t\t\toutput,\n",
        "\t\t\t\tn_segments=200,\n",
        "\t\t\t\tcompactness=0.01,\n",
        "\t\t\t\tsigma=5.0,\n",
        "\t\t\t\tselem_radius=3\n",
        "\t\t\t)\n",
        "\n",
        "            image_id = train_ids[i]\n",
        "            # Save masks as PNGs\n",
        "            Image.fromarray(better_seg.astype(np.uint8), mode=\"L\").save(save_dir / f\"{image_id}_mask.png\")\n",
        "\n",
        "    # Update pseudo masks to be used in training\n",
        "    new_mask = [save_dir / f\"{image_id}_mask.png\" for image_id in train_ids]\n",
        "    trainloader.dataset.update_pseudo_mask(new_mask)\n",
        "\n",
        "    ### Train model on the refined masks\n",
        "    model.train()\n",
        "    trainloader.dataset.transforms = train_transforms\n",
        "    for i, (images, _, cams, _) in enumerate(tqdm(trainloader)):\n",
        "        images = images.to(device)\n",
        "        cams = cams.to(device)\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)[\"out\"]\n",
        "        loss = loss_fn(outputs, cams)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.argmax(outputs, dim=1)\n",
        "        miou += utils.mean_iou(pred, cams, num_classes=NUM_CLASSES) * batch_size\n",
        "\n",
        "    miou /= num_train_samples\n",
        "    print(f\"Epoch [{epoch + 1}/{TRAIN_EPOCHS}], Loss: {loss.item():.4f}, mIoU: {miou:.4f}\")\n",
        "\n",
        "    # Save model checkpoint\n",
        "    save_path = MODEL_DIR.joinpath(f\"cam_deeplab_epoch_{epoch + 1}.pth\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model saved at {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fQq6SzcyjWgj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQq6SzcyjWgj",
        "outputId": "663e27f3-3f4b-4208-fbd4-4352e6ac7ec6"
      },
      "outputs": [],
      "source": [
        "save_epochs = torch.arange(5, TRAIN_EPOCHS + 1, 5)\n",
        "\n",
        "for epoch in save_epochs:\n",
        "    model_name = f\"cam_deeplab_epoch_{epoch}.pth\"\n",
        "\n",
        "    # Load model\n",
        "    model = deeplabv3_resnet50(weights=None)\n",
        "    model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
        "    model.load_state_dict(torch.load(MODEL_DIR.joinpath(model_name), weights_only=True))\n",
        "    model.to(device)\n",
        "\n",
        "    # Evaluate model\n",
        "    model.eval()\n",
        "    num_test_samples = len(testloader.dataset)\n",
        "    miou = 0\n",
        "    with torch.no_grad():\n",
        "        for images, segs, _, _ in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            segs = segs.to(device)\n",
        "            batch_size = images.size(0)\n",
        "\n",
        "            outputs = model(images)[\"out\"]\n",
        "            preds = (torch.argmax(outputs, dim=1) > 0)\n",
        "\n",
        "            miou += utils.mean_iou(preds, segs, num_classes=2) * batch_size\n",
        "\n",
        "        miou /= num_test_samples\n",
        "        print(f\"Model: {model_name},Mean IoU: {miou:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
