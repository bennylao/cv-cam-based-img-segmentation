{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6460a86",
   "metadata": {},
   "source": [
    "# Baseline Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48708f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_dir(cwd: pathlib.Path = pathlib.Path().resolve(), anchor=\"README.md\") -> pathlib.Path:\n",
    "    \"\"\"\n",
    "    Get the root directory of the project by searching for a specific anchor file. \n",
    "    i.e. find the root directory where anchor file README.md/.git is located.\n",
    "    \n",
    "    Args:\n",
    "        cwd (pathlib.Path): Current working directory.\n",
    "        anchor (str): The name of the anchor file to search for.\n",
    "\n",
    "    Returns:\n",
    "        pathlib.Path: The root directory of the project.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the anchor file is not found in any parent directories.\n",
    "    \"\"\"\n",
    "    # Check if the anchor file exists in the current working directory\n",
    "    # If it does, return the current working directory\n",
    "    # If it doesn't, check the parent directories until the anchor file is found\n",
    "    if cwd.joinpath(anchor).exists():\n",
    "        return cwd\n",
    "    else:\n",
    "        for parent in cwd.parents:\n",
    "            if (parent / anchor).exists():\n",
    "                return parent\n",
    "    \n",
    "    # If the anchor file is not found in any parent directories, raise an error\n",
    "    raise FileNotFoundError(f\"Anchor file '{anchor}' not found in any parent directories of {cwd}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e50a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git repository information\n",
    "REPO_GIT_OWNER = \"bennylao\"\n",
    "REPO_NAME = \"cv-cam-based-img-segmentation\"\n",
    "\n",
    "\n",
    "### Logics to set up paths based on the environment (Google Colab or local machine) ###\n",
    "COLAB_ROOT_PATH = pathlib.Path(\"/content\")\n",
    "IS_COLAB = COLAB_ROOT_PATH.exists()\n",
    "\n",
    "if IS_COLAB:\n",
    "    # Working on Google Colab\n",
    "    from google.colab import drive\n",
    "\n",
    "    # Mount Google Drive\n",
    "    DRIVE_PATH = COLAB_ROOT_PATH.joinpath(\"drive\")\n",
    "    drive.flush_and_unmount()\n",
    "    drive.mount(str(DRIVE_PATH))\n",
    "\n",
    "    # Load git credentials from Google Drive\n",
    "    DRIVE_FOLDER_PATH = DRIVE_PATH.joinpath(\"MyDrive\", \"Colab Notebooks\")\n",
    "    if DRIVE_FOLDER_PATH.exists():\n",
    "        with open(DRIVE_FOLDER_PATH.joinpath(\"git_credentials.json\"), \"r\") as f:\n",
    "            git_config = json.load(f)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Config file not found at {DRIVE_FOLDER_PATH}\")\n",
    "\n",
    "    # Set up Git credentials\n",
    "    GIT_USER_NAME = git_config[\"GIT_USER_NAME\"]\n",
    "    GIT_TOKEN = git_config[\"GIT_TOKEN\"]\n",
    "    GIT_USER_EMAIL = git_config[\"GIT_USER_EMAIL\"]\n",
    "\n",
    "    !git config --global user.email {GIT_USER_EMAIL}\n",
    "    !git config --global user.name {GIT_USER_NAME}\n",
    "\n",
    "    # Set up project paths\n",
    "    CURRENT_PATH = pathlib.Path().resolve()\n",
    "    ROOT = COLAB_ROOT_PATH.joinpath(REPO_NAME)\n",
    "    DATA_DIR = ROOT.joinpath(\"data\")\n",
    "    MODEL_DIR = DRIVE_FOLDER_PATH.joinpath(\"models\")\n",
    "    OUTPUT_DIR = DRIVE_FOLDER_PATH.joinpath(\"output\")\n",
    "\n",
    "    # Clone repo\n",
    "    GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{REPO_GIT_OWNER}/{REPO_NAME}.git\"\n",
    "\n",
    "    if not ROOT.exists():\n",
    "        !git clone --depth 1 \"{GIT_PATH}\" \"{ROOT}\"\n",
    "    else:\n",
    "        print(f\"Git repo already cloned at {ROOT}\")\n",
    "        !git -C \"{ROOT}\" pull\n",
    "\n",
    "else:\n",
    "    # Working on local machine\n",
    "    CURRENT_PATH = pathlib.Path().resolve()\n",
    "    ROOT = get_root_dir(CURRENT_PATH, anchor=\"README.md\")\n",
    "    DATA_DIR = ROOT.joinpath(\"data\")\n",
    "    MODEL_DIR = ROOT.joinpath(\"models\")\n",
    "    OUTPUT_DIR = ROOT.joinpath(\"output\")\n",
    "\n",
    "# Create folder if not exist\n",
    "if not DATA_DIR.exists():\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created data directory at {DATA_DIR}\")\n",
    "\n",
    "if not OUTPUT_DIR.exists():\n",
    "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created output directory at {OUTPUT_DIR}\")\n",
    "\n",
    "if not MODEL_DIR.exists():\n",
    "    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Created model directory at {MODEL_DIR}\")\n",
    "\n",
    "# Add root path to sys.path\n",
    "sys.path.append(str(ROOT))\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"Runtime: {'Google Colab' if IS_COLAB else 'Local Machine'}\")\n",
    "print(f\"{CURRENT_PATH=}\")\n",
    "print(f\"{ROOT=}\")\n",
    "print(f\"{DATA_DIR=}\")\n",
    "print(f\"{MODEL_DIR=}\")\n",
    "print(f\"{OUTPUT_DIR=}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498a9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from src import utils\n",
    "from src.models.baseline_unet import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMAGE_SIZE = 256\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "TRAIN_EPOCHS = 20\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45476cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pin_memory = True if torch.cuda.is_available() else False\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# load dataset\n",
    "train_transforms = utils.Compose([\n",
    "    utils.PILToTensor(),\n",
    "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    utils.ConvertMaskToBinary(),\n",
    "    utils.RandomHorizontalFlip(flip_prob=0.5),\n",
    "    utils.RandomVerticalFlip(flip_prob=0.5),\n",
    "    utils.RandomRotation(degrees=30),\n",
    "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "test_transforms = utils.Compose([\n",
    "    utils.PILToTensor(),\n",
    "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    utils.ConvertMaskToBinary(),\n",
    "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "trainset, testset = utils.construct_dataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    train_transforms=train_transforms,\n",
    "    test_transforms=test_transforms,\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(\n",
    "    trainset,\n",
    "    batch_size=TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "testloader = DataLoader(\n",
    "    testset,\n",
    "    batch_size=TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=pin_memory,\n",
    ")\n",
    "\n",
    "model = UNet(num_classes=2).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(\n",
    "    model.parameters(), lr=0.01,\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4,\n",
    "    nesterov=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model.train()\n",
    "num_train_samples = len(trainloader.dataset)\n",
    "\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{TRAIN_EPOCHS}\")\n",
    "    miou = 0\n",
    "    for i, (images, segs, _, _) in enumerate(tqdm(trainloader)):\n",
    "        images = images.to(device)\n",
    "        segs = segs.to(device)\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)[\"out\"]\n",
    "        loss = loss_fn(outputs, segs)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        pred = torch.argmax(outputs, dim=1)\n",
    "        miou += utils.mean_iou(pred, segs, num_classes=NUM_CLASSES) * batch_size\n",
    "\n",
    "    miou /= num_train_samples\n",
    "    print(f\"Epoch [{epoch + 1}/{TRAIN_EPOCHS}], Loss: {loss.item():.4f}, mIoU: {miou:.4f}\")\n",
    "\n",
    "    # Save model checkpoint\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        save_path = MODEL_DIR.joinpath(f\"baseline_unet_epoch_{epoch + 1}.pth\")\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "        print(f\"Model saved at {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87d3100",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_epochs = torch.arange(5, TRAIN_EPOCHS + 1, 5)\n",
    "\n",
    "for epoch in save_epochs:\n",
    "    model_name = f\"baseline_unet_epoch_{epoch}.pth\"\n",
    "\n",
    "    # Load model\n",
    "    model = UNet(num_classes=2)\n",
    "    model.load_state_dict(torch.load(MODEL_DIR.joinpath(model_name), weights_only=True))\n",
    "    model.to(device)\n",
    "\n",
    "    # Evaluate model\n",
    "    model.eval()\n",
    "    num_test_samples = len(testloader.dataset)\n",
    "    miou = 0\n",
    "    with torch.no_grad():\n",
    "        for images, segs, _, _ in tqdm(testloader):\n",
    "            images = images.to(device)\n",
    "            segs = segs.to(device)\n",
    "            batch_size = images.size(0)\n",
    "\n",
    "            outputs = model(images)[\"out\"]\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            miou += utils.mean_iou(preds, segs, num_classes=NUM_CLASSES) * batch_size\n",
    "\n",
    "        miou /= num_test_samples\n",
    "        print(f\"Model: {model_name},Mean IoU: {miou:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
