{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a6460a86",
      "metadata": {
        "id": "a6460a86"
      },
      "source": [
        "# Baseline Unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a48708f7",
      "metadata": {
        "id": "a48708f7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import json\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e024487f",
      "metadata": {
        "id": "e024487f"
      },
      "outputs": [],
      "source": [
        "def get_root_dir(cwd: pathlib.Path = pathlib.Path().resolve(), anchor=\"README.md\") -> pathlib.Path:\n",
        "    \"\"\"\n",
        "    Get the root directory of the project by searching for a specific anchor file.\n",
        "    i.e. find the root directory where anchor file README.md/.git is located.\n",
        "\n",
        "    Args:\n",
        "        cwd (pathlib.Path): Current working directory.\n",
        "        anchor (str): The name of the anchor file to search for.\n",
        "\n",
        "    Returns:\n",
        "        pathlib.Path: The root directory of the project.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the anchor file is not found in any parent directories.\n",
        "    \"\"\"\n",
        "    # Check if the anchor file exists in the current working directory\n",
        "    # If it does, return the current working directory\n",
        "    # If it doesn't, check the parent directories until the anchor file is found\n",
        "    if cwd.joinpath(anchor).exists():\n",
        "        return cwd\n",
        "    else:\n",
        "        for parent in cwd.parents:\n",
        "            if (parent / anchor).exists():\n",
        "                return parent\n",
        "\n",
        "    # If the anchor file is not found in any parent directories, raise an error\n",
        "    raise FileNotFoundError(f\"Anchor file '{anchor}' not found in any parent directories of {cwd}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1e50a417",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e50a417",
        "outputId": "e862c841-c5f1-44f2-eed9-923511930fa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n",
            "Cloning into '/content/cv-cam-based-img-segmentation'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 31 (delta 2), reused 25 (delta 1), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (31/31), 49.56 KiB | 16.52 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "==================================================\n",
            "Runtime: Google Colab\n",
            "CURRENT_PATH=PosixPath('/content')\n",
            "ROOT=PosixPath('/content/cv-cam-based-img-segmentation')\n",
            "DATA_DIR=PosixPath('/content/cv-cam-based-img-segmentation/data')\n",
            "MODEL_DIR=PosixPath('/content/drive/MyDrive/Colab Notebooks/models')\n",
            "OUTPUT_DIR=PosixPath('/content/drive/MyDrive/Colab Notebooks/output')\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Git repository information\n",
        "REPO_GIT_OWNER = \"bennylao\"\n",
        "REPO_NAME = \"cv-cam-based-img-segmentation\"\n",
        "\n",
        "\n",
        "### Logics to set up paths based on the environment (Google Colab or local machine) ###\n",
        "COLAB_ROOT_PATH = pathlib.Path(\"/content\")\n",
        "IS_COLAB = COLAB_ROOT_PATH.exists()\n",
        "\n",
        "if IS_COLAB:\n",
        "    # Working on Google Colab\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Mount Google Drive\n",
        "    DRIVE_PATH = COLAB_ROOT_PATH.joinpath(\"drive\")\n",
        "    drive.flush_and_unmount()\n",
        "    drive.mount(str(DRIVE_PATH))\n",
        "\n",
        "    # Load git credentials from Google Drive\n",
        "    DRIVE_FOLDER_PATH = DRIVE_PATH.joinpath(\"MyDrive\", \"Colab Notebooks\")\n",
        "    if DRIVE_FOLDER_PATH.exists():\n",
        "        with open(DRIVE_FOLDER_PATH.joinpath(\"git_credentials.json\"), \"r\") as f:\n",
        "            git_config = json.load(f)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Config file not found at {DRIVE_FOLDER_PATH}\")\n",
        "\n",
        "    # Set up Git credentials\n",
        "    GIT_USER_NAME = git_config[\"GIT_USER_NAME\"]\n",
        "    GIT_TOKEN = git_config[\"GIT_TOKEN\"]\n",
        "    GIT_USER_EMAIL = git_config[\"GIT_USER_EMAIL\"]\n",
        "\n",
        "    !git config --global user.email {GIT_USER_EMAIL}\n",
        "    !git config --global user.name {GIT_USER_NAME}\n",
        "\n",
        "    # Set up project paths\n",
        "    CURRENT_PATH = pathlib.Path().resolve()\n",
        "    ROOT = COLAB_ROOT_PATH.joinpath(REPO_NAME)\n",
        "    DATA_DIR = ROOT.joinpath(\"data\")\n",
        "    MODEL_DIR = DRIVE_FOLDER_PATH.joinpath(\"models\")\n",
        "    OUTPUT_DIR = DRIVE_FOLDER_PATH.joinpath(\"output\")\n",
        "\n",
        "    # Clone repo\n",
        "    GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{REPO_GIT_OWNER}/{REPO_NAME}.git\"\n",
        "\n",
        "    if not ROOT.exists():\n",
        "        !git clone --depth 1 \"{GIT_PATH}\" \"{ROOT}\"\n",
        "    else:\n",
        "        print(f\"Git repo already cloned at {ROOT}\")\n",
        "        !git -C \"{ROOT}\" pull\n",
        "\n",
        "else:\n",
        "    # Working on local machine\n",
        "    CURRENT_PATH = pathlib.Path().resolve()\n",
        "    ROOT = get_root_dir(CURRENT_PATH, anchor=\"README.md\")\n",
        "    DATA_DIR = ROOT.joinpath(\"data\")\n",
        "    MODEL_DIR = ROOT.joinpath(\"models\")\n",
        "    OUTPUT_DIR = ROOT.joinpath(\"output\")\n",
        "\n",
        "# Create folder if not exist\n",
        "if not DATA_DIR.exists():\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created data directory at {DATA_DIR}\")\n",
        "\n",
        "if not OUTPUT_DIR.exists():\n",
        "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created output directory at {OUTPUT_DIR}\")\n",
        "\n",
        "if not MODEL_DIR.exists():\n",
        "    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created model directory at {MODEL_DIR}\")\n",
        "\n",
        "# Add root path to sys.path\n",
        "sys.path.append(str(ROOT))\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"Runtime: {'Google Colab' if IS_COLAB else 'Local Machine'}\")\n",
        "print(f\"{CURRENT_PATH=}\")\n",
        "print(f\"{ROOT=}\")\n",
        "print(f\"{DATA_DIR=}\")\n",
        "print(f\"{MODEL_DIR=}\")\n",
        "print(f\"{OUTPUT_DIR=}\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6498a9e3",
      "metadata": {
        "id": "6498a9e3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from src import utils\n",
        "from src.models.unet import UNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "41ca25ac",
      "metadata": {
        "id": "41ca25ac"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "IMAGE_SIZE = 256\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "TRAIN_EPOCHS = 20\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "TEST_BATCH_SIZE = 32\n",
        "NUM_WORKERS = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d45476cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d45476cc",
        "outputId": "486eb6a9-4681-401f-8f24-1dd163414b5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 792M/792M [00:45<00:00, 17.5MB/s]\n",
            "100%|██████████| 19.2M/19.2M [00:02<00:00, 7.88MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pin_memory = True if torch.cuda.is_available() else False\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# load dataset\n",
        "train_transforms = utils.Compose([\n",
        "    utils.PILToTensor(),\n",
        "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    utils.ConvertMaskToBinary(),\n",
        "    utils.RandomHorizontalFlip(flip_prob=0.5),\n",
        "    utils.RandomVerticalFlip(flip_prob=0.5),\n",
        "    utils.RandomRotation(degrees=30),\n",
        "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "test_transforms = utils.Compose([\n",
        "    utils.PILToTensor(),\n",
        "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    utils.ConvertMaskToBinary(),\n",
        "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "trainset, testset = utils.construct_dataset(\n",
        "    data_dir=DATA_DIR,\n",
        "    train_transforms=train_transforms,\n",
        "    test_transforms=test_transforms,\n",
        ")\n",
        "\n",
        "trainloader = DataLoader(\n",
        "    trainset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "testloader = DataLoader(\n",
        "    testset,\n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "model = UNet(num_classes=2).to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(\n",
        "    model.parameters(), lr=0.01,\n",
        "    momentum=0.9,\n",
        "    weight_decay=1e-4,\n",
        "    nesterov=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7f4a5800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f4a5800",
        "outputId": "258a9082-c7d7-4ae5-c786-479ad2c8e405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:35<00:00,  4.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.5379, mIoU: 0.5731\n",
            "Epoch 2/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/20], Loss: 0.3339, mIoU: 0.7146\n",
            "Epoch 3/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/20], Loss: 0.3187, mIoU: 0.7600\n",
            "Epoch 4/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/20], Loss: 0.2753, mIoU: 0.7831\n",
            "Epoch 5/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/20], Loss: 0.2370, mIoU: 0.8021\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/baseline_unet_epoch_5.pth\n",
            "Epoch 6/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/20], Loss: 0.2357, mIoU: 0.8137\n",
            "Epoch 7/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/20], Loss: 0.1943, mIoU: 0.8209\n",
            "Epoch 8/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/20], Loss: 0.2589, mIoU: 0.8276\n",
            "Epoch 9/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/20], Loss: 0.2026, mIoU: 0.8348\n",
            "Epoch 10/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/20], Loss: 0.2169, mIoU: 0.8403\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/baseline_unet_epoch_10.pth\n",
            "Epoch 11/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/20], Loss: 0.1947, mIoU: 0.8436\n",
            "Epoch 12/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/20], Loss: 0.1902, mIoU: 0.8479\n",
            "Epoch 13/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/20], Loss: 0.2319, mIoU: 0.8525\n",
            "Epoch 14/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/20], Loss: 0.1929, mIoU: 0.8527\n",
            "Epoch 15/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/20], Loss: 0.1651, mIoU: 0.8583\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/baseline_unet_epoch_15.pth\n",
            "Epoch 16/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/20], Loss: 0.1699, mIoU: 0.8619\n",
            "Epoch 17/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/20], Loss: 0.2283, mIoU: 0.8631\n",
            "Epoch 18/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/20], Loss: 0.1460, mIoU: 0.8652\n",
            "Epoch 19/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/20], Loss: 0.2221, mIoU: 0.8668\n",
            "Epoch 20/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 161/161 [00:34<00:00,  4.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/20], Loss: 0.1328, mIoU: 0.8706\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/baseline_unet_epoch_20.pth\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "model.train()\n",
        "num_train_samples = len(trainloader.dataset)\n",
        "\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{TRAIN_EPOCHS}\")\n",
        "    miou = 0\n",
        "    for i, (images, segs, _, _) in enumerate(tqdm(trainloader)):\n",
        "        images = images.to(device)\n",
        "        segs = segs.to(device)\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, segs)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.argmax(outputs, dim=1)\n",
        "        miou += utils.mean_iou(pred, segs, num_classes=NUM_CLASSES) * batch_size\n",
        "\n",
        "    miou /= num_train_samples\n",
        "    print(f\"Epoch [{epoch + 1}/{TRAIN_EPOCHS}], Loss: {loss.item():.4f}, mIoU: {miou:.4f}\")\n",
        "\n",
        "    # Save model checkpoint\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        save_path = MODEL_DIR.joinpath(f\"baseline_unet_epoch_{epoch + 1}.pth\")\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Model saved at {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b87d3100",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b87d3100",
        "outputId": "a3f5e471-03cb-4a10-c727-448d45a40d68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69/69 [00:05<00:00, 12.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: baseline_unet_epoch_5.pth,Mean IoU: 0.7920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69/69 [00:06<00:00, 10.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: baseline_unet_epoch_10.pth,Mean IoU: 0.8290\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69/69 [00:05<00:00, 11.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: baseline_unet_epoch_15.pth,Mean IoU: 0.8533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 69/69 [00:05<00:00, 11.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: baseline_unet_epoch_20.pth,Mean IoU: 0.8656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "save_epochs = torch.arange(5, TRAIN_EPOCHS + 1, 5)\n",
        "\n",
        "for epoch in save_epochs:\n",
        "    model_name = f\"baseline_unet_epoch_{epoch}.pth\"\n",
        "\n",
        "    # Load model\n",
        "    model = UNet(num_classes=2)\n",
        "    model.load_state_dict(torch.load(MODEL_DIR.joinpath(model_name), weights_only=True))\n",
        "    model.to(device)\n",
        "\n",
        "    # Evaluate model\n",
        "    model.eval()\n",
        "    num_test_samples = len(testloader.dataset)\n",
        "    miou = 0\n",
        "    with torch.no_grad():\n",
        "        for images, segs, _, _ in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            segs = segs.to(device)\n",
        "            batch_size = images.size(0)\n",
        "\n",
        "            outputs = model(images)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "            miou += utils.mean_iou(preds, segs, num_classes=NUM_CLASSES) * batch_size\n",
        "\n",
        "        miou /= num_test_samples\n",
        "        print(f\"Model: {model_name}, Mean IoU: {miou:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
