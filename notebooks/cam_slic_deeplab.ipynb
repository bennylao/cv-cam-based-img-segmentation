{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a6460a86",
      "metadata": {
        "id": "a6460a86"
      },
      "source": [
        "# SLIC + GradCAM++ DeepLabv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a48708f7",
      "metadata": {
        "id": "a48708f7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import json\n",
        "import pathlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e024487f",
      "metadata": {
        "id": "e024487f"
      },
      "outputs": [],
      "source": [
        "def get_root_dir(cwd: pathlib.Path = pathlib.Path().resolve(), anchor=\"README.md\") -> pathlib.Path:\n",
        "    \"\"\"\n",
        "    Get the root directory of the project by searching for a specific anchor file.\n",
        "    i.e. find the root directory where anchor file README.md/.git is located.\n",
        "\n",
        "    Args:\n",
        "        cwd (pathlib.Path): Current working directory.\n",
        "        anchor (str): The name of the anchor file to search for.\n",
        "\n",
        "    Returns:\n",
        "        pathlib.Path: The root directory of the project.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the anchor file is not found in any parent directories.\n",
        "    \"\"\"\n",
        "    # Check if the anchor file exists in the current working directory\n",
        "    # If it does, return the current working directory\n",
        "    # If it doesn't, check the parent directories until the anchor file is found\n",
        "    if cwd.joinpath(anchor).exists():\n",
        "        return cwd\n",
        "    else:\n",
        "        for parent in cwd.parents:\n",
        "            if (parent / anchor).exists():\n",
        "                return parent\n",
        "\n",
        "    # If the anchor file is not found in any parent directories, raise an error\n",
        "    raise FileNotFoundError(f\"Anchor file '{anchor}' not found in any parent directories of {cwd}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1e50a417",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e50a417",
        "outputId": "68f5696a-6583-4db6-8298-bcca00750100"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "==================================================\n",
            "Runtime: Google Colab\n",
            "CURRENT_PATH=PosixPath('/content')\n",
            "ROOT=PosixPath('/content/cv-cam-based-img-segmentation')\n",
            "DATA_DIR=PosixPath('/content/cv-cam-based-img-segmentation/data')\n",
            "MODEL_DIR=PosixPath('/content/drive/MyDrive/Colab Notebooks/models')\n",
            "OUTPUT_DIR=PosixPath('/content/drive/MyDrive/Colab Notebooks/output')\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "# Git repository information\n",
        "REPO_GIT_OWNER = \"bennylao\"\n",
        "REPO_NAME = \"cv-cam-based-img-segmentation\"\n",
        "\n",
        "\n",
        "### Logics to set up paths based on the environment (Google Colab or local machine) ###\n",
        "COLAB_ROOT_PATH = pathlib.Path(\"/content\")\n",
        "IS_COLAB = COLAB_ROOT_PATH.exists()\n",
        "\n",
        "if IS_COLAB:\n",
        "    # Working on Google Colab\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Mount Google Drive\n",
        "    DRIVE_PATH = COLAB_ROOT_PATH.joinpath(\"drive\")\n",
        "    drive.flush_and_unmount()\n",
        "    drive.mount(str(DRIVE_PATH))\n",
        "\n",
        "    # Load git credentials from Google Drive\n",
        "    DRIVE_FOLDER_PATH = DRIVE_PATH.joinpath(\"MyDrive\", \"Colab Notebooks\")\n",
        "    if DRIVE_FOLDER_PATH.exists():\n",
        "        with open(DRIVE_FOLDER_PATH.joinpath(\"git_credentials.json\"), \"r\") as f:\n",
        "            git_config = json.load(f)\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"Config file not found at {DRIVE_FOLDER_PATH}\")\n",
        "\n",
        "    # Set up Git credentials\n",
        "    GIT_USER_NAME = git_config[\"GIT_USER_NAME\"]\n",
        "    GIT_TOKEN = git_config[\"GIT_TOKEN\"]\n",
        "    GIT_USER_EMAIL = git_config[\"GIT_USER_EMAIL\"]\n",
        "\n",
        "    !git config --global user.email {GIT_USER_EMAIL}\n",
        "    !git config --global user.name {GIT_USER_NAME}\n",
        "\n",
        "    # Set up project paths\n",
        "    CURRENT_PATH = pathlib.Path().resolve()\n",
        "    ROOT = COLAB_ROOT_PATH.joinpath(REPO_NAME)\n",
        "    DATA_DIR = ROOT.joinpath(\"data\")\n",
        "    MODEL_DIR = DRIVE_FOLDER_PATH.joinpath(\"models\")\n",
        "    OUTPUT_DIR = DRIVE_FOLDER_PATH.joinpath(\"output\")\n",
        "\n",
        "    # Clone repo\n",
        "    GIT_PATH = f\"https://{GIT_TOKEN}@github.com/{REPO_GIT_OWNER}/{REPO_NAME}.git\"\n",
        "\n",
        "    if not ROOT.exists():\n",
        "        !git clone --depth 1 \"{GIT_PATH}\" \"{ROOT}\"\n",
        "\n",
        "else:\n",
        "    # Working on local machine\n",
        "    CURRENT_PATH = pathlib.Path().resolve()\n",
        "    ROOT = get_root_dir(CURRENT_PATH, anchor=\"README.md\")\n",
        "    DATA_DIR = ROOT.joinpath(\"data\")\n",
        "    MODEL_DIR = ROOT.joinpath(\"models\")\n",
        "    OUTPUT_DIR = ROOT.joinpath(\"output\")\n",
        "\n",
        "# Create folder if not exist\n",
        "if not DATA_DIR.exists():\n",
        "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created data directory at {DATA_DIR}\")\n",
        "\n",
        "if not OUTPUT_DIR.exists():\n",
        "    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created output directory at {OUTPUT_DIR}\")\n",
        "\n",
        "if not MODEL_DIR.exists():\n",
        "    MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    print(f\"Created model directory at {MODEL_DIR}\")\n",
        "\n",
        "# Add root path to sys.path\n",
        "sys.path.append(str(ROOT))\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"Runtime: {'Google Colab' if IS_COLAB else 'Local Machine'}\")\n",
        "print(f\"{CURRENT_PATH=}\")\n",
        "print(f\"{ROOT=}\")\n",
        "print(f\"{DATA_DIR=}\")\n",
        "print(f\"{MODEL_DIR=}\")\n",
        "print(f\"{OUTPUT_DIR=}\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6498a9e3",
      "metadata": {
        "id": "6498a9e3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models.segmentation import deeplabv3_resnet50\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from skimage.segmentation import slic\n",
        "from skimage.morphology import opening, closing, disk\n",
        "from src import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "41ca25ac",
      "metadata": {
        "id": "41ca25ac"
      },
      "outputs": [],
      "source": [
        "# Set Hyperparameters\n",
        "IMAGE_SIZE = 256\n",
        "NUM_CLASSES = 3\n",
        "\n",
        "TRAIN_EPOCHS = 10\n",
        "TRAIN_BATCH_SIZE = 64\n",
        "TEST_BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Path to cam dataset\n",
        "model_name = \"cam_deeplab_epoch_5.pth\"\n",
        "CAM_DIR = DATA_DIR.joinpath(\"cam_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d45476cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d45476cc",
        "outputId": "05d85c62-3ec7-4f68-ef6a-93ea28083df2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pin_memory = True if torch.cuda.is_available() else False\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define transforms\n",
        "train_transforms = utils.Compose([\n",
        "    utils.PILToTensor(),\n",
        "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    utils.ConvertMaskToBinary(),\n",
        "    utils.RandomHorizontalFlip(flip_prob=0.5),\n",
        "    utils.RandomVerticalFlip(flip_prob=0.5),\n",
        "    utils.RandomRotation(degrees=30),\n",
        "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
        "    utils.FormatCAM(isRaw=False),\n",
        "])\n",
        "test_transforms = utils.Compose([\n",
        "    utils.PILToTensor(),\n",
        "    utils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "    utils.ConvertMaskToBinary(),\n",
        "    utils.ToDtype(dtype=torch.float32, scale=True),\n",
        "    utils.FormatCAM(isRaw=False),\n",
        "])\n",
        "superpixel_transforms = utils.Compose([\n",
        "\tutils.PILToTensor(),\n",
        "\tutils.ResizeImgAndMask(size=(IMAGE_SIZE, IMAGE_SIZE)),\n",
        "\tutils.ToDtype(dtype=torch.float32, scale=True),\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "trainset, testset = utils.construct_dataset(\n",
        "    data_dir=DATA_DIR,\n",
        "    train_transforms=train_transforms,\n",
        "    test_transforms=test_transforms,\n",
        "    cam_dir=CAM_DIR,\n",
        "    raw_cam=False,\n",
        ")\n",
        "trainloader = DataLoader(\n",
        "    trainset,\n",
        "    batch_size=TRAIN_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "testloader = DataLoader(\n",
        "    testset,\n",
        "    batch_size=TEST_BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "\n",
        "with open(DATA_DIR / \"train_ids.json\", \"r\") as f:\n",
        "    train_ids = json.load(f)\n",
        "\n",
        "# Load model\n",
        "model = deeplabv3_resnet50(weights=None)\n",
        "model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
        "model.load_state_dict(torch.load(MODEL_DIR.joinpath(model_name), weights_only=True))\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(\n",
        "    model.parameters(),\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "590e6d72",
      "metadata": {
        "id": "590e6d72"
      },
      "source": [
        "## Train deeplabv3 on the generated CAM masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a11126ac",
      "metadata": {
        "id": "a11126ac"
      },
      "outputs": [],
      "source": [
        "def refine_with_soft_voting( # summs probability per class instead of class values + opening and closing smoothing\n",
        "    image_tensor,\n",
        "    prob_map,\n",
        "    n_segments: int = 200,\n",
        "    compactness: float = 10.0,\n",
        "    sigma: float = 1.0,\n",
        "    selem_radius: int = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Refine a per-pixel probability map by superpixel soft-voting, with smoothing.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    image_tensor : torch.Tensor\n",
        "        Input image in CHW format ([3, H, W]).\n",
        "    prob_map : np.ndarray\n",
        "        Softmax output of shape (H, W, C) giving per-pixel class probabilities.\n",
        "    n_segments : int\n",
        "        Number of superpixels for SLIC.\n",
        "    compactness : float\n",
        "        Compactness parameter for SLIC.\n",
        "    sigma : float\n",
        "        Gaussian smoothing parameter for SLIC.\n",
        "    selem_radius : int or None\n",
        "        Radius for morphological opening+closing. If None, no smoothing is done.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    smoothed : np.ndarray or None\n",
        "        If `selem_radius` is given, the result after opening+closing, else None.\n",
        "    refined : np.ndarray\n",
        "        Hard labels after superpixel soft-voting, shape (H, W), dtype int.\n",
        "    superpixels : np.ndarray\n",
        "        The SLIC label map, shape (H, W), dtype int.\n",
        "    \"\"\"\n",
        "    # Convert image tensor to HWC numpy\n",
        "    img = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "    prob = prob_map.permute(1, 2, 0).cpu().numpy()  # Convert to HWC\n",
        "\n",
        "    # 1) Compute superpixels\n",
        "    superpixels = slic(\n",
        "        img,\n",
        "        n_segments=n_segments,\n",
        "        compactness=compactness,\n",
        "        sigma=sigma,\n",
        "        start_label=0\n",
        "    )\n",
        "    # print(f\"SLIC produced {superpixels.max()+1} superpixels; shape = {superpixels.shape}\")\n",
        "\n",
        "    # 2) Soft‐voting within each superpixel\n",
        "    H, W, C = prob.shape\n",
        "    refined = np.zeros((H, W), dtype=np.int32)\n",
        "    for sp_val in np.unique(superpixels):\n",
        "        mask = (superpixels == sp_val)\n",
        "        sp_probs = prob[mask]           # shape: (n_pixels_in_sp, C)\n",
        "        summed = sp_probs.sum(axis=0)       # shape: (C,)\n",
        "        refined[mask] = np.argmax(summed)\n",
        "\n",
        "    # 3) Optional morphological smoothing\n",
        "    smoothed = None\n",
        "    if selem_radius is not None:\n",
        "        selem = disk(selem_radius)\n",
        "        # Opening then closing to remove small islands & fill gaps\n",
        "        smooth0 = opening(refined.astype(np.uint8), selem)\n",
        "        smoothed = closing(smooth0, selem)\n",
        "\n",
        "    return smoothed, refined, superpixels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7f4a5800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f4a5800",
        "outputId": "69b9c386-9c61-46e9-b627-6938fd1bb2d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [13:02<00:00,  6.58it/s]\n",
            "100%|██████████| 81/81 [00:35<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.3400, mIoU: 0.7101\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_1.pth\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [12:59<00:00,  6.60it/s]\n",
            "100%|██████████| 81/81 [00:35<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Loss: 0.3245, mIoU: 0.7082\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_2.pth\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [13:00<00:00,  6.59it/s]\n",
            "100%|██████████| 81/81 [00:35<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Loss: 0.3131, mIoU: 0.7049\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_3.pth\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [13:00<00:00,  6.59it/s]\n",
            "100%|██████████| 81/81 [00:35<00:00,  2.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Loss: 0.3163, mIoU: 0.7024\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_4.pth\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [13:00<00:00,  6.59it/s]\n",
            "100%|██████████| 81/81 [00:35<00:00,  2.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Loss: 0.3261, mIoU: 0.6996\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_5.pth\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [13:01<00:00,  6.58it/s]\n",
            "100%|██████████| 81/81 [00:35<00:00,  2.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Loss: 0.3200, mIoU: 0.6965\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_6.pth\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [13:04<00:00,  6.56it/s]\n",
            "100%|██████████| 81/81 [00:36<00:00,  2.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Loss: 0.3078, mIoU: 0.6915\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_7.pth\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [13:05<00:00,  6.55it/s]\n",
            "100%|██████████| 81/81 [00:35<00:00,  2.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Loss: 0.3048, mIoU: 0.6876\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_8.pth\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [13:04<00:00,  6.56it/s]\n",
            "100%|██████████| 81/81 [00:35<00:00,  2.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/10], Loss: 0.3452, mIoU: 0.6832\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_9.pth\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5144/5144 [13:04<00:00,  6.56it/s]\n",
            "100%|██████████| 81/81 [00:35<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/10], Loss: 0.3228, mIoU: 0.6792\n",
            "Model saved at /content/drive/MyDrive/Colab Notebooks/models/self_train_deeplab_epoch_10.pth\n"
          ]
        }
      ],
      "source": [
        "# Train model\n",
        "num_train_samples = len(trainloader.dataset)\n",
        "\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{TRAIN_EPOCHS}\")\n",
        "    miou = 0\n",
        "    # Configure the path where new pseudo masks are saved\n",
        "    save_dir = DATA_DIR / f\"superpixel_refined_mask_{epoch}\"\n",
        "    save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ### Generate refined masks for training\n",
        "    model.eval()\n",
        "    trainloader.dataset.transforms = superpixel_transforms\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(len(train_ids))):\n",
        "\n",
        "            image, _, _, _ = trainloader.dataset[i]\n",
        "            image = image.to(device)\n",
        "\n",
        "            output = model(image.unsqueeze(0))[\"out\"].cpu().squeeze(0)\n",
        "\n",
        "            # Refine masks with superpixels and some smoothing\n",
        "            better_seg, _, _  = refine_with_soft_voting(\n",
        "                image.cpu(),\n",
        "\t\t\t\toutput,\n",
        "\t\t\t\tn_segments=200,\n",
        "\t\t\t\tcompactness=0.01,\n",
        "\t\t\t\tsigma=5.0,\n",
        "\t\t\t\tselem_radius=3\n",
        "\t\t\t)\n",
        "\n",
        "            image_id = train_ids[i]\n",
        "            # Save masks as PNGs\n",
        "            Image.fromarray(better_seg.astype(np.uint8), mode=\"L\").save(save_dir / f\"{image_id}_mask.png\")\n",
        "\n",
        "    # Update pseudo masks to be used in training\n",
        "    new_mask = [save_dir / f\"{image_id}_mask.png\" for image_id in train_ids]\n",
        "    trainloader.dataset.update_pseudo_mask(new_mask)\n",
        "\n",
        "    ### Train model on the refined masks\n",
        "    model.train()\n",
        "    trainloader.dataset.transforms = train_transforms\n",
        "    for i, (images, _, cams, _) in enumerate(tqdm(trainloader)):\n",
        "        images = images.to(device)\n",
        "        cams = cams.to(device)\n",
        "        batch_size = images.size(0)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)[\"out\"]\n",
        "        loss = loss_fn(outputs, cams)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = torch.argmax(outputs, dim=1)\n",
        "        miou += utils.mean_iou(pred, cams, num_classes=NUM_CLASSES) * batch_size\n",
        "\n",
        "    miou /= num_train_samples\n",
        "    print(f\"Epoch [{epoch + 1}/{TRAIN_EPOCHS}], Loss: {loss.item():.4f}, mIoU: {miou:.4f}\")\n",
        "\n",
        "    # Save model checkpoint\n",
        "    save_path = MODEL_DIR.joinpath(f\"self_train_deeplab_epoch_{epoch + 1}.pth\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model saved at {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fQq6SzcyjWgj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQq6SzcyjWgj",
        "outputId": "ec73917c-7028-4792-ad5e-387d2b0edf66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_1.pth,Mean IoU: 0.7450\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_2.pth,Mean IoU: 0.7501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_3.pth,Mean IoU: 0.7540\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_4.pth,Mean IoU: 0.7581\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_5.pth,Mean IoU: 0.7621\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_6.pth,Mean IoU: 0.7661\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_7.pth,Mean IoU: 0.7696\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_8.pth,Mean IoU: 0.7729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_9.pth,Mean IoU: 0.7744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 35/35 [00:10<00:00,  3.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: self_train_deeplab_epoch_10.pth,Mean IoU: 0.7761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "save_epochs = torch.arange(1, TRAIN_EPOCHS + 1, 1)\n",
        "\n",
        "for epoch in save_epochs:\n",
        "    model_name = f\"self_train_deeplab_epoch_{epoch}.pth\"\n",
        "\n",
        "    # Load model\n",
        "    model = deeplabv3_resnet50(weights=None)\n",
        "    model.classifier[4] = nn.Conv2d(256, NUM_CLASSES, kernel_size=1)\n",
        "    model.load_state_dict(torch.load(MODEL_DIR.joinpath(model_name), weights_only=True))\n",
        "    model.to(device)\n",
        "\n",
        "    # Evaluate model\n",
        "    model.eval()\n",
        "    num_test_samples = len(testloader.dataset)\n",
        "    miou = 0\n",
        "    with torch.no_grad():\n",
        "        for images, segs, _, _ in tqdm(testloader):\n",
        "            images = images.to(device)\n",
        "            segs = segs.to(device)\n",
        "            batch_size = images.size(0)\n",
        "\n",
        "            outputs = model(images)[\"out\"]\n",
        "            preds = (torch.argmax(outputs, dim=1) > 0)\n",
        "\n",
        "            miou += utils.mean_iou(preds, segs, num_classes=2) * batch_size\n",
        "\n",
        "        miou /= num_test_samples\n",
        "        print(f\"Model: {model_name},Mean IoU: {miou:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
